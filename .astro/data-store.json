[["Map",1,2,9,10,53,54],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.5.5","content-config-digest","18bc59923c544a46","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[]},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"mermaid\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{\"light\":\"github-light\",\"dark\":\"catppuccin-frappe\"},\"wrap\":false,\"transformers\":[{\"name\":\"@shikijs/transformers:notation-diff\"},{\"name\":\"@shikijs/transformers:notation-highlight\"},{\"name\":\"@shikijs/transformers:notation-highlight-word\"},{\"name\":\"@shikijs/transformers:notation-focus\"},{\"name\":\"@shikijs/transformers:notation-error-level\"},{\"name\":\"@shikijs/transformers:meta-highlight\"}]},\"remarkPlugins\":[null,null],\"rehypePlugins\":[null,[null,{\"customClassNames\":{\"calloutClass\":\"callout\",\"calloutTitleClass\":\"callout-title\",\"calloutContentClass\":\"callout-content\"}}],null,null],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"responsiveImages\":false,\"serializeConfig\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false},\"legacy\":{\"collections\":false}}","article",["Map",11,12,25,26,34,35,43,44],"a-mail-server-in-a-kubernetes-cluster",{"id":11,"data":13,"body":22,"filePath":23,"digest":24,"deferredRender":21},{"title":14,"description":15,"permalink":11,"thumbnail":16,"authors":17,"publishedAt":19,"isAvailable":20,"isDisplayedOnHomepage":21},"A mail server in a kubernetes cluster","You maybe know postfix mail server, but do you know how to run it in a kubernetes cluster ? This article will show you how to run a mail server in a kubernetes cluster.","https://placehold.co/1200x630",[18],"baptiste_bronsin",["Date","2030-01-01T00:00:00.000Z"],false,true,"# Welcome to Explainer\n\nExplainer is a documentation boilerplate designed to help you create beautiful, responsive, and accessible web documentation using [Astro](https://astro.build). This project combines the power of Astro with [Tailwind CSS](https://tailwindcss.com) and [TypeScript](https://www.typescriptlang.org) to provide a smooth development experience.\n\n## Why Explainer?\n\nDocumentation is often overlooked, but it's essential for the adoption and effective use of your project.\nExplainer fills an important gap in the technical documentation ecosystem. While Vue has robust solutions like Vitepress, the React ecosystem suffers from a lack of alternatives that don't depend on Next.js. Most documentation frameworks for React are closely tied to Next.js, which can be limiting for many projects.\n\nThis is where Astro, and by extension Explainer, particularly shines. Astro offers remarkable flexibility by allowing you to integrate any technological component related to your business. You can easily incorporate React, Vue, Svelte components, or even standard web elements according to your specific needs.\n\nThis agnostic approach allows you to create documentation that perfectly aligns with your existing technology stack, without forcing you to adopt a particular ecosystem. Whether you work with React, Vue, or other frameworks, Explainer adapts to your needs rather than the other way around.","src/content/articles/a-mail-server-in-a-kubernetes-cluster.mdx","bc7226769b4676f9","how-i-configured-my-own-home-server",{"id":25,"data":27,"body":22,"filePath":32,"digest":33,"deferredRender":21},{"title":28,"description":29,"permalink":25,"thumbnail":16,"authors":30,"publishedAt":31,"isAvailable":20,"isDisplayedOnHomepage":21},"How I configured my own home server ?","A personal home server is a great way to learn about server administration, networking and security. In this article, I will show you how I configured my own home server to host my personal projects and services.",[18],["Date","2030-01-01T00:00:00.000Z"],"src/content/articles/how-i-configured-my-own-home-server.mdx","1e6743e0c89949d2","welcome",{"id":34,"data":36,"body":22,"filePath":41,"digest":42,"deferredRender":21},{"title":37,"description":38,"permalink":34,"thumbnail":16,"authors":39,"publishedAt":40,"isAvailable":20,"isDisplayedOnHomepage":20},"Discover Explainer","Discover Explainer is a tool that helps you create beautiful, responsive, and accessible web documentation using Astro. It's built with Astro, Tailwind CSS, and TypeScript.",[18],["Date","2030-01-01T00:00:00.000Z"],"src/content/articles/welcome.mdx","8a013229fcf9e392","how-to-avoid-too-many-a-and-aaaa-dns-records-in-your-dns-zone-file",{"id":43,"data":45,"body":22,"filePath":51,"digest":52,"deferredRender":21},{"title":46,"description":47,"permalink":43,"thumbnail":48,"authors":49,"publishedAt":50,"isAvailable":20,"isDisplayedOnHomepage":21},"How to avoid too many A and AAAA DNS records in your DNS zone file ?","Managing numerous A and AAAA records in your DNS zone file can become cumbersome, especially when updating public IP addresses. This article explores using CNAME records as a more efficient alternative to simplify DNS management.","/images/articles/dns-records.png",[18],["Date","2030-01-01T00:00:00.000Z"],"src/content/articles/how-to-avoid-too-many-a-and-aaaa-dns-records-in-your-dns-zone-file.mdx","94329b42791aaada","project",["Map",55,56,105,106,123,124,145,146,160,161,172,173,184,185],"beep",{"id":55,"data":57,"body":102,"filePath":103,"digest":104,"deferredRender":21},{"title":58,"description":59,"permalink":55,"logo":60,"contributors":61,"publishedAt":76,"tags":77,"links":96,"status":99,"type":100,"license":101,"isAvailable":21,"isDisplayedOnHomepage":21},"Beep","Beep is a web application that aims to implement the same functionalities as the Discord platform. This project is being developed by the entire DevOps class of 2023-2026 at Polytech Montpellier.","/images/project/beep/logo.png",[18,62,63,64,65,66,67,68,69,70,71,72,73,74,75],"dorian_grasset","duratm","hugo_ponthieu","nathael_bonnal","nayrode","isalyne_llinares","giada_de_martino","poptart_coral","razano","benoit_planche","courtcircuits","stheoulle","theotchlx","thomas_broine",["Date","2026-01-30T00:00:00.000Z"],[78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95],"web","react","typescript","tailwindcss","rust","axum","postgresql","garage","redis","keycloak","docker","kubernetes","github actions","argocd","helm","grafana","prometheus","loki",{"website":97,"github":98},"https://beep.ovh","https://github.com/beep-industries","active","university","Apache-2.0","# A Discord Alternative by DevOps Students\n\nThe Polytech Montpellier DevOps class of 2023-2026 has a \"fil rouge\" project named **Beep**. This project aims to create a web application that replicates the functionalities of [the Discord platform](https://discord.com/).\n\n\u003Cdiv className=\"flex justify-center items-center\">\n  \u003Cimg\n    src=\"https://upload.wikimedia.org/wikipedia/fr/4/4f/Discord_Logo_sans_texte.svg\"\n    alt=\"Discord logo\"\n    width={100}\n  />\n\u003C/div>\n\n## Overview\n\nBeep is designed to offer a comprehensive communication platform for communities, friends, and professionals. It provides a seamless and integrated user experience with a focus on real-time communication and collaboration.\n\n## Functionalities\n\nLike Discord, Beep allows users to:\n\n- Create and manage servers (both private and public)\n- Send and receive messages in real-time (text and file sharing)\n- Join and participate in voice channels\n- Customize user profiles and server settings\n\nThe project leverages modern web technologies to ensure performance, scalability, and a responsive design:\n\n- **Frontend:** React, TypeScript, and TailwindCSS\n- **Backend:** AdonisJS with PostgreSQL\n\n## Interface\n\n### User Authentication\n\nBeep offers a user-friendly authentication process, including traditional login/signup methods and QR code authentication for enhanced user convenience.\n\n\u003Cimg src=\"/images/project/beep/login-page.png\" alt=\"Beep login page\" />\n\n### User Dashboard\n\nOnce logged in, users are greeted with an intuitive interface:\n\n- **Left Sidebar:** Displays the servers the user is part of.\n- **Main Area:** Shows the messages exchanged in the current channel.\n- **Right Sidebar:** Lists the channels available in the selected server.\n\n\u003Cimg src=\"/images/project/beep/server-page.png\" alt=\"Beep home page\" />\n\n## Team Work\n\nThe Beep project is developed using an Agile methodology, with the project fragmented into sprint periods. Each sprint focuses on specific features and improvements, ensuring continuous progress and regular updates.\n\n### Team Structure\n\nAt the beginning of the project, the class was divided into several teams, each responsible for different aspects of the application:\n| Message Team | File Team | Voice Team |\n|--------------|-----------|------------|\n| 5 students | 5 students | 5 students |\n| Responsible for developing the messaging functionalities, including sending and receiving text messages in real time. | Responsible for developing the file sharing functionalities, allowing users to upload and download files in channels. | Responsible for developing the voice channel functionalities, enabling users to communicate via voice in real time. |\n\nAfter this short period, the teams were reorganized to focus on the integration of all functionalities into a single cohesive application. We created Gitlab issues to track the progress of each feature and ensure that all teams were aligned with the overall project goals. Each issues had a status:\n| Status | Description |\n|--------|-------------|\n| To Develop | The feature needs to be developed by the team. |\n| To Accept | The issue has been described and needs to be accepted by the team before development begins. |\n| Ready | The feature is ready to be developed by the team. |\n| In Progress (WIP) | The feature is currently being developed by the team. |\n| In Review | The feature has been implemented and is awaiting review by the team. |\n| Done | The feature has been successfully implemented and is ready for deployment. |\n\nWhen a feature is in the 'In Review' status, it requires two approvals from team members before it can be marked as 'Done' and merged. To facilitate this process, a team member created a Discord bot that assigns reviewers. If a reviewer does not accept the task within five minutes, the bot automatically selects another student to conduct the review.\n\n## Architecture\n\nThe architecture of Beep is designed to be scalable, maintainable, and robust. Key components include:\n\n- **Containerization:** Docker\n- **Orchestration:** Kubernetes\n- **CI/CD Pipeline:** GitLab CI\n- **Deployments:** ArgoCD\n- **Monitoring and Logging:** Grafana, Prometheus, and Loki\n\nThis setup ensures that Beep can handle a large number of users and provide a reliable service with minimal downtime.\n\n## Future Enhancements\n\nOur roadmap for Beep includes several exciting features and improvements:\n\n- **Bot Integration:** Allowing users to create and integrate bots for various functionalities.\n- **Enhanced Security:** Implementing advanced security measures to protect user data.\n- **Mobile App:** Developing a mobile application for on-the-go access.\n\n## Conclusion\n\nBeep is more than just a project; it's a testament to the skills and dedication of the Polytech Montpellier DevOps class of 2023-2026. We are excited to continue developing this platform and look forward to the positive impact it will have on communication and collaboration.","src/content/projects/beep.mdx","e9ea9d9b41eba032","opensource",{"id":105,"data":107,"body":120,"filePath":121,"digest":122,"deferredRender":21},{"title":108,"description":109,"permalink":105,"contributors":110,"publishedAt":111,"tags":112,"status":99,"type":119,"isAvailable":21,"isDisplayedOnHomepage":21},"Open source projects","I'm interested in open source projects and I contribute to several of them. Here are some of the projects I'm involved in.",[18],["Date","2026-03-01T00:00:00.000Z"],[105,113,114,115,116,117,118],"contribution","github","open source","community","collaboration","open source contribution","personal","# Open source projects\n\nThe open source ecosystem is a vibrant and dynamic space that fosters collaboration, innovation, and community engagement. Contributing to open source projects allows developers to give back to the community, improve their skills and work on projects that they are passionate about. In this section, I will share some of the open source projects that I'm involved in, along with my contributions and experiences.\n\n## My Contributions\n\nI have taken an interest in some open source projects and tried to contribute to them in various ways.\n\n### FerrisKey\n\nFerrisKey ([github](https://github.com/ferriskey)) is an open source project that provides a secure and user-friendly IAM (Identity and Access Management) solution. It wants to replace the Keycloak project and offers more security features and better performance. I have contributed to FerrisKey by fixing bugs and improving documentation.\n\nHere are my contributions:\n\n- [[issue #655] Document the API endpoints](https://github.com/ferriskey/ferriskey/pull/728)\n- [[issue #755] Add default client scopes when creating a realm](https://github.com/ferriskey/ferriskey/pull/768)\n\n### Docker mail server\n\nDocker mail server ([github](https://github.com/docker-mailserver/docker-mailserver)) is an open source project that provides a simple and efficient way to set up a mail server using Docker. This community has a main problem: they don't provide an API to manage the mail server, which makes it difficult to automate tasks and integrate with other systems.\n\nSo I created a project called [docker-mailserver-api](https://github.com/baptistebronsin/docker-mailserver-api) that provides a RESTful API in Rust to manage the Docker mail server. This project allows users to easily manage their mail server, automate tasks, and integrate with other systems. However, this project is still in its early stages and I'm facing some challenges to interact with the Docker mail server process. I'm actively working on it and I hope to make it available for the community soon.","src/content/projects/opensource.mdx","0da27e6b7c58cbc5","plannify",{"id":123,"data":125,"body":142,"filePath":143,"digest":144,"deferredRender":21},{"title":126,"description":127,"permalink":123,"logo":128,"contributors":129,"publishedAt":130,"tags":131,"links":138,"status":99,"type":119,"license":141,"isAvailable":21,"isDisplayedOnHomepage":21},"Plannify","Plannify is a web application that allows truck drivers to enter their days and generate personalized reports. It will also aim to provide a connection with the employer to facilitate the management of working hours, tournees, and more.","/images/project/plannify/logo.png",[18],["Date","2025-06-03T00:00:00.000Z"],[78,79,80,81,132,133,84,134,88,89,135,136,91,92,137],"nestjs","prisma","minio","mail server","gitlab ci","cronjob",{"website":139,"gitlab":140},"https://app.plannify.be","https://gitlab.com/plannify-group","AGPL-3.0","# A truck driver application\n\nPlannify is a web application designed specifically for truck drivers, enabling them to log their daily activities and generate personalized reports. The platform also aims to facilitate communication with employers, streamlining the management of working hours, routes, and other essential tasks.\n\n## Why is it a personal project ?\n\nWhen I was in my second year of university, my father asked me to print blank papers with a specific format for his truck driver activities. As a programmer, I thought it would be more efficient to create a web application that could generate these reports automatically. This idea led to the development of Plannify, which has since evolved into a comprehensive tool for truck drivers.\n\nToday, Plannify has daily users and is actively used by my father and his colleagues. The application continues to grow, with plans to add more features and improve the user experience.\n\n## Features\n\nThe main features of Plannify include:\n\n- **Daily Activity Logging**: Truck drivers can easily enter their daily activities, including working hours, rest periods and overnight stays.\n  | Attribute | Type | Description |\n  |-----------|------|-------------|\n  | `date` | date | The date of the day |\n  | `startTime` | hour | The start time of the day |\n  | `endTime` | hour or undefined | The end time of the day |\n  | `restTime` | hour | The total rest time taken during the day |\n  | `overnightStay` | boolean | Indicates whether the driver stayed overnight |\n\n- **Report Generation**: Users can generate monthly reports based on their logged activities, which can be exported in PDF format.\n- **Employer Connection** (_currently in development_): The application aims to provide a connection with employers, allowing them to manage working hours, routes, and other relevant information more efficiently.\n- **User-Friendly Application**: Plannify is designed to be intuitive and easy to use, ensuring that truck drivers can quickly log their activities without any hassle. And I think human must be at the center of the application, so I try to make it as simple as possible without hidding weird behaviors.\n\n## Technologies Used\n\nPlannify is built using modern web technologies, including:\n\n- **Frontend**: React, TypeScript, and TailwindCSS for a responsive and user-friendly interface.\n- **Backend**: NestJS with Prisma and PostgreSQL for robust data management and server-side logic.\n- **File Storage**: MinIO for secure file storage and management.\n- **Containerization**: Docker for easy deployment and scalability.\n- **Orchestration**: Kubernetes for managing containerized applications and ensuring high availability.\n- **CI/CD**: GitLab CI for continuous integration and deployment, ensuring that updates are rolled out smoothly.\n- **Monitoring**: Argocd and Helm for managing deployments and scheduled tasks.\n- **Email Notifications**: A mail server for sending notifications and updates to users.\n- **Cron Jobs**: Scheduled tasks for automated report generation, account management and other periodic activities.\n\n\u003Cdiv className=\"grid grid-rows-2 grid-cols-2 sm:grid-rows-1 sm:grid-cols-4 gap-4 w-full\">\n  \u003Cimg\n    src=\"/images/project/plannify/dashboard-1.png\"\n    alt=\"Plannify home dashboard\"\n  />\n  \u003Cimg\n    src=\"/images/project/plannify/dashboard-2.png\"\n    alt=\"Plannify workday dashboard\"\n  />\n  \u003Cimg\n    src=\"/images/project/plannify/dashboard-3.png\"\n    alt=\"Plannify reports dashboard\"\n  />\n  \u003Cimg\n    src=\"/images/project/plannify/dashboard-4.png\"\n    alt=\"Plannify account dashboard\"\n  />\n\u003C/div>\n\nI also used the PWA (Progressive Web App) features to allow users to install the application on their devices and use it as a native mobile application.\n\n## Automation and Deployment\n\n### Environments\n\nI have set up multiple environments for Plannify to ensure smooth development, testing, and production processes:\n\n- **Staging**: A staging environment for testing new features and updates before they go live.\n- **Production**: The live environment where users access the application.\n\n### CI\n\nPlannify uses GitLab CI for continuous integration, ensuring that code changes are automatically tested and deployed.\n\nFor the frontend, I have a pipeline that checks the code quality (linting), builds the application and stores the build artifacts in the GitLab registry. For the backend, like the frontend, I have the same pipeline and I also run the tests to ensure that everything is working as expected.\n\n\u003Cdiv>\n  \u003Cimg\n    className=\"max-w-[100%] object-contain\"\n    src=\"/images/project/plannify/backend-pipeline.png\"\n    alt=\"Plannify backend pipeline\"\n  />\n\u003C/div>\n\n### CD\n\nFor continuous deployment, I use ArgoCD to manage the deployment of the application to the staging and production environments. This allows for automated rollouts and rollbacks, ensuring that updates are deployed smoothly without downtime. Thats allows me to pratice the GitOps principles.\n\n\u003Cdiv>\n  \u003Cimg\n    className=\"max-w-[100%] object-contain\"\n    src=\"/images/project/plannify/argocd.png\"\n    alt=\"Plannify argocd operator\"\n  />\n\u003C/div>\n\n### Helm\n\nI use Helm to manage the Kubernetes deployments of Plannify. Helm charts allow me to define, install, and upgrade the application in a consistent manner across different environments. This simplifies the deployment process and ensures that all dependencies are managed effectively.\n\n## Automations\n\n### Sending Reports\n\nI have implemented a kubernetes cron job to automate the generation and sending of reports. This job runs at the beginning of each month, generating reports for users who agreed to receive them. The reports are then sent via email, ensuring that users have access to their activity summaries without needing to manually generate them.\n\n### Account Management\n\nI have also set up a cron job to manage user accounts. This job runs daily and delete accounts that have not been logged into for more than 6 months. This helps maintain the application's performance and ensures that user data is managed responsibly.\n\n### Backups\n\nData backups are crucial for any application, and Plannify is no exception. I have implemented a backup strategy that includes:\n\n- **Database Backups**: Regular backups of the PostgreSQL database to ensure that user data is safe and can be restored in case of any issues.\n- **File Storage Backups**: Backups of files stored in MinIO to prevent data loss in case of hardware failures or other issues.\n\nEach backup is stored securely in a separate location to ensure data integrity and availability. I also have a cron job that runs daily to create these backups, ensuring that the application can recover quickly in case of any unexpected events.\n\n## Future Plans\n\nI want to continue improving Plannify and add a link between employers and employees. This will allow a better visibility for truck drivers and their daily activities, and will also help employers manage their workforce more effectively.\n\nI also plan to continue offering the application for free and without any ads, as I believe it's important to provide a valuable tool for truck drivers without any financial barriers.\n\n## Conclusion\n\nPlannify is my main personal project, and I'm proud of the progress it has made since its inception. The application has evolved from a simple idea into a comprehensive tool that is actively used by truck drivers. I'm excited about the future of Plannify and the potential it has to make a positive impact on the lives of truck drivers.","src/content/projects/plannify.mdx","073fb1b95ac9234b","polyclount",{"id":145,"data":147,"body":22,"filePath":158,"digest":159,"deferredRender":21},{"title":148,"description":149,"permalink":150,"logo":151,"contributors":152,"publishedAt":153,"links":154,"status":157,"type":119,"license":141,"isAvailable":20,"isDisplayedOnHomepage":20},"Polycount","Polycount is my first Javascript web application. It allows users to assign expenses to group activities (like Tricount).","polycount","/images/project/polycount.png",[18],["Date","2025-01-01T00:00:00.000Z"],{"website":155,"gitlab":156},"https://polycount.baptistebronsin.be","https://gitlab.com/baptiste.bronsin/polycount","archived","src/content/projects/polyclount.mdx","5119d095b2ecd444","operator-price",{"id":160,"data":162,"body":22,"filePath":170,"digest":171,"deferredRender":21},{"title":163,"description":164,"permalink":160,"contributors":165,"publishedAt":166,"links":167,"status":157,"type":119,"license":141,"isAvailable":20,"isDisplayedOnHomepage":20},"Operator Price","Operator price tells a user whether it's better to buy a smartphone with or without a phone operator.",[18],["Date","2023-04-27T00:00:00.000Z"],{"website":168,"gitlab":169},"https://prix-operateur.baptistebronsin.be/","https://gitlab.com/baptiste.bronsin/prix_operateur.git","src/content/projects/operator-price.mdx","dac1b4c02cc29ade","portfolio",{"id":172,"data":174,"body":22,"filePath":182,"digest":183,"deferredRender":21},{"title":175,"description":176,"permalink":172,"contributors":177,"publishedAt":178,"links":179,"status":99,"type":119,"license":141,"isAvailable":20,"isDisplayedOnHomepage":20},"Portfolio","The Portfolio project is the website you are currently visiting. It is a personal project that I developed to present my career and my projects.",[18],["Date","2025-01-01T00:00:00.000Z"],{"website":180,"github":181},"https://baptistebronsin.be","https://github.com/baptistebronsin/portfolio.git","src/content/projects/portfolio.mdx","59233c55a382bdf8","postgres-backup",{"id":184,"data":186,"body":196,"filePath":197,"digest":198,"deferredRender":21},{"title":187,"description":188,"permalink":184,"contributors":189,"publishedAt":190,"tags":191,"links":194,"status":99,"type":119,"license":141,"isAvailable":21,"isDisplayedOnHomepage":21},"Postgres Backup","Postgres Backup is a personal project that allows you to backup PostgreSQL databases to a S3 compatible storage.",[18],["Date","2025-07-03T00:00:00.000Z"],[84,192,134,193,88,89,137],"bash","S3",{"github":195},"https://github.com/baptistebronsin/postgres-backup","# A database backup solution for PostgreSQL\n\nI work on many projects that use PostgreSQL and I needed a simple way to back up my databases. Initially, I connected manually to each database and used the `pg_dump` command to create backup files. This process quickly became tedious and error-prone, especially when managing multiple databases on a recurring schedule. Sometimes I even forgot to run the backups because I had other things to do on my Sundays ☀️.\n\n## Features\n\nThis project is designed to run in containerized environments (docker compose and kubernetes) and can be automated using cron jobs. It allows you to backup your PostgreSQL databases to a S3 compatible storage, such as MinIO, AWS S3, Cloudflare R2, etc.\n\nTo be used in every project, this script is designed to be flexible and easy to configure. You can specify the databases you want to backup, the compression algorithm and the storage location.\n\n## Arguments\n\n| Variable                 | Description                                                                   | Required | Example                      |\n| ------------------------ | ----------------------------------------------------------------------------- | -------- | ---------------------------- |\n| DB_HOST                  | The host of the database                                                      | yes      | postgres                     |\n| DB_PORT                  | The port of the database                                                      | yes      | 5432                         |\n| DB_USER                  | The user of the database                                                      | yes      | postgres                     |\n| DB_PASSWORD              | The password of the database                                                  | yes      | postgres                     |\n| DB_NAME                  | The name of the database                                                      | yes      | plannify                     |\n| ---                      | ---                                                                           | ---      |\n| BACKUP_DIR               | The directory of the backup                                                   | no       | 'daily', 'weekly', 'monthly' |\n| BACKUP_MAX_BEFORE_DELETE | The maximum number of backup before deleting the oldest one                   | no       | 7                            |\n| BACKUP_COMPRESSION       | The compression method to use for the backup file (no compression by default) | no       | gzip, xz                     |\n| ---                      | ---                                                                           | ---      |\n| S3_ENDPOINT              | The bucket endpoint                                                           | yes      | https://...                  |\n| S3_ACCESS_TOKEN          | The access token of your provider account                                     | yes      | 1234567890                   |\n| S3_SECRET_ACCESS_TOKEN   | The secret access token of your provider account                              | yes      | 1234567890                   |\n| S3_BUCKET                | The S3 bucket of your account                                                 | yes      | plannify                     |\n\n## Technologies Used\n\nThis project is built using basic Bash scripting and Docker to create a containerized backup solution that can easily run in any environment.\n\n## Dockerfile\n\nThe Dockerfile is based on the official Postgres image and includes all necessary dependencies to run the backup script.\n\nThe container runs as a specific user, `backupuser`, who has the required permissions to access the database and perform backups securely.\n\n## CI\n\nA basic GitHub Action CI pipeline is configured to build the Docker image on each tag push.","src/content/projects/postgres-backup.mdx","2e038876c46e4749"]